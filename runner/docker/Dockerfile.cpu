# CPU-only image with llama.cpp built and runner binary

# ---- Stage 1: build llama.cpp (CPU)
FROM ubuntu:22.04 AS llama
RUN apt-get update && apt-get install -y git build-essential cmake
WORKDIR /opt
RUN git clone --depth=1 https://github.com/ggerganov/llama.cpp.git
WORKDIR /opt/llama.cpp
RUN cmake -S . -B build -DBUILD_SHARED_LIBS=OFF && cmake --build build -j

# ---- Stage 2: build runner (Rust)
FROM rust:1.82 AS builder
WORKDIR /work
COPY . .
ENV LLAMA_CPP_DIR=/opt/llama.cpp/build
COPY --from=llama /opt/llama.cpp/build /opt/llama.cpp/build
RUN apt-get update && apt-get install -y pkg-config clang && \
    cargo build -p runner-cli --release

# ---- Stage 3: runtime
FROM debian:12-slim
WORKDIR /app
RUN apt-get update && apt-get install -y ca-certificates && rm -rf /var/lib/apt/lists/*
COPY --from=builder /work/target/release/runner-cli /usr/local/bin/runner
COPY --from=llama /opt/llama.cpp/build /opt/llama.cpp/build
ENV LLAMA_CPP_DIR=/opt/llama.cpp/build
EXPOSE 8080
CMD ["runner","serve"]

